# RAG-Document-QA-with-Streamlit
This project implements a Retrieval-Augmented Generation (RAG) system for answering questions from a collection of documents. It uses LangChain for document processing, vector databases for semantic search, and provides a simple Streamlit web app for interactive Q&amp;A.

Features

ðŸ“‚ Upload and query your own documents (PDF, text, etc.).

ðŸ”Ž Semantic search with embeddings for accurate retrieval.

ðŸ’¬ Chat-style interface to ask questions about your documents.

âš¡ Works with OpenAI API or local LLMs (GPT4All, HuggingFace models) â€” no quota required if running locally.

ðŸš€ Easy to deploy on Streamlit Cloud or run locally.

Tech Stack

Python

LangChain (langchain, langchain-community, langchain-openai)

ChromaDB (vector store)

Streamlit (UI)

OpenAI / GPT4All / HuggingFace (LLM options)

âš¡ Pro tip: In your README.md, you can also add:

Setup instructions (venv + requirements.txt)

Usage examples (terminal & Streamlit)

Screenshot/GIF of the app in action
